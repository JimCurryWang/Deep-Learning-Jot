{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET\n",
    "\n",
    "The Pytorch implementation for the ResNet paper: Deep Residual Learning for Image Recognition \n",
    "\n",
    "### Paper \n",
    "<a href=\"https://arxiv.org/abs/1512.03385\">Deep Residual Learning for Image Recognition</a>\n",
    "\n",
    "### Implementation\n",
    "- The image is resized with its shorter side randomly sampled in [256, 480] for scale augmentation. \n",
    "- A 224Ã—224 crop is randomly sampled from an image or its horizontal flip. \n",
    "- Adopt batch normalization (BN) right after each convolution and before activation. (Does not need bias term)\n",
    "- Do not use dropout.\n",
    "\n",
    "### ResNet-50 Schematic diagram\n",
    "\n",
    "<a href=\"https://drive.google.com/file/d/1B3T3Yv5_f4MvXlu5nG-AeByEMCV2N9QY/view?usp=sharing\">ResNet-50 Schematic Diagram</a>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"img/ResNet50.png\" width=\"100%\"/>\n",
    "</div>\n",
    "\n",
    "### Structure\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"img/ResNet-structure.jpeg\" width=\"100%\"/>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"img/ResNet-bottleneck.jpeg\" width=\"50%\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    '''A \"bottleneck\" building block for ResNet-50/101/152\n",
    "    '''\n",
    "    def __init__(self, in_channels, intermediate_channels, identity_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        \n",
    "        # ResNet use 4 times expansion in the entire design\n",
    "        self.expansion = 4\n",
    "        \n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "        # 1x1 Conv \n",
    "        self.conv1 = nn.Conv2d(in_channels, intermediate_channels, \n",
    "                               kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
    "        \n",
    "        # 3x3 Conv (bottleneck)\n",
    "        self.conv2 = nn.Conv2d(intermediate_channels, intermediate_channels, \n",
    "                               kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
    "        \n",
    "        # 1x1 Conv\n",
    "        self.conv3 = nn.Conv2d(intermediate_channels, intermediate_channels * self.expansion,\n",
    "                               kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        # When the start point and end point dimension is different...\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    '''\n",
    "        torch.nn.Conv2d(in_channels, out_channels, \n",
    "                    kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "    \n",
    "        torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    \n",
    "        torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "        torch.nn.AdaptiveAvgPool2d(output_size = (n,m))\n",
    "        torch.nn.Linear(in_features, out_features, bias=True)\n",
    "    '''\n",
    "    def __init__(self, Block, layers, image_channels=3, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        # Conv1 (7,7,64), s=2, p=3\n",
    "        self.in_channels = 64\n",
    "        self.Conv1 = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        ) \n",
    "        \n",
    "        # 3x3 Max Pooling, s=2, p=1\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNet layers (Residual block layers staking)\n",
    "        self.layer1 = self._make_layer(Block, layers[0], intermediate_channels=64,  stride=1)\n",
    "        self.layer2 = self._make_layer(Block, layers[1], intermediate_channels=128, stride=2)\n",
    "        self.layer3 = self._make_layer(Block, layers[2], intermediate_channels=256, stride=2)\n",
    "        self.layer4 = self._make_layer(Block, layers[3], intermediate_channels=512, stride=2)\n",
    "\n",
    "        # Adaptive Average Pooling (1x1 outputsize)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # FC (2048 -> 1000)\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.Conv1(x)        \n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "\n",
    "        # AVG Pool & FC\n",
    "        # count how many batch and reshape it to one-dimension\n",
    "        # i.g. (batch_size,2048,1,1) -> (batch_size,2048)\n",
    "        x = self.avgpool(x) \n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, Block, num_residual_blocks, intermediate_channels, stride):\n",
    "        '''Creating the numbers of blocks stacked\n",
    "        i.g.\n",
    "            ResNet-50:  [3,4,6,3]\n",
    "            ResNet-101: [3,4,23,3]\n",
    "            ResNet-152: [3,8,36,3]\n",
    "        '''\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        \n",
    "        # Adjust the channel size for the first block in each layer (Do identiry downsample)\n",
    "        # we need to adapt the Identity (skip connection) \n",
    "        # so it can be able to be added to the layer that's ahead\n",
    "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, intermediate_channels * 4, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(intermediate_channels * 4),\n",
    "            )\n",
    "\n",
    "        layers.append(\n",
    "            Block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
    "        )\n",
    "\n",
    "        # Update in_channels size for the following block\n",
    "        # The expansion size is always 4 for ResNet 50,101,152\n",
    "        self.in_channels = intermediate_channels * 4 \n",
    "\n",
    "        # For example for first ResNet layer, sencond ~ last block: \n",
    "        # 256 will be mapped to 64 as intermediate layer, then finally back to 256(64*4),\n",
    "        # Hence no identity downsample is needed\n",
    "        #                     (256,56,56)\n",
    "        # -> conv(1x1,64)  -> (64,56,56)\n",
    "        # -> conv(3x3,64)  -> (64,56,56)\n",
    "        # -> conv(1x1,256) -> (256,56,56)\n",
    "\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(Block(self.in_channels, intermediate_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet_test(img_channel=3, num_classes=1000):\n",
    "    '''fake structure just for test\n",
    "    '''\n",
    "    return ResNet(Block, [2, 1, 1, 1], img_channel, num_classes)\n",
    "\n",
    "def ResNet50(img_channel=3, num_classes=1000):\n",
    "    return ResNet(Block, [3, 4, 6, 3], img_channel, num_classes)\n",
    "\n",
    "\n",
    "def ResNet101(img_channel=3, num_classes=1000):\n",
    "    return ResNet(Block, [3, 4, 23, 3], img_channel, num_classes)\n",
    "\n",
    "\n",
    "def ResNet152(img_channel=3, num_classes=1000):\n",
    "    return ResNet(Block, [3, 8, 36, 3], img_channel, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Block(\n",
       "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing for block \n",
    "block_src = Block(in_channels=256, intermediate_channels=64)\n",
    "block_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (Conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Block(\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Block(\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Block(\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Block(\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ResNet_test(img_channel=3, num_classes=1000)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1000])\n"
     ]
    }
   ],
   "source": [
    "# testing for whole ResNet\n",
    "def test():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    net = ResNet101(img_channel=3, num_classes=1000)\n",
    "    y = net(torch.randn(4, 3, 224, 224)).to(device)\n",
    "    print(y.size())\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision \n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "\n",
    "#Load train and test set:\n",
    "data = torchvision.datasets.CIFAR10(\n",
    "    root='../CIFAR10',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data,batch_size=128,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(data,batch_size=128,shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and loss function\n",
    "model = ResNet101(img_channel=3, num_classes=1000)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.9)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] Loss: 0.030661647319793702\n",
      "[1/2] Loss: 0.024976458549499512\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    closs = 0\n",
    "    \n",
    "    for i,batch in enumerate(train_loader):\n",
    "        \n",
    "        inputs, output = batch\n",
    "        inputs = inputs.to(device)\n",
    "        output = output.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        prediction = model(inputs)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(prediction, output)\n",
    "        closs = loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Show progress for every 100th times\n",
    "        if i%100 == 0:\n",
    "            print('[{}/{}] Loss: {}'.format(epoch+1,epochs,closs/100))\n",
    "            closs = 0\n",
    "            \n",
    "            \n",
    "    correctHits=0\n",
    "    total=0     \n",
    "    for i,batch in enumerate(test_loader):\n",
    "        inputs, output = batch\n",
    "        inputs = inputs.to(device)\n",
    "        output = output.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        prediction = model(inputs)\n",
    "        # returns max as well as its index\n",
    "        _,prediction = torch.max(prediction.data,1)  \n",
    "        total += output.size(0)\n",
    "        correctHits += (prediction==output).sum().item()\n",
    "    print('Accuracy on epoch ',epoch+1,'= ',str((correctHits/total)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

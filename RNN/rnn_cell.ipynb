{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN cell in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.RNNCell() & torch.nn.RNN()\n",
    "### torch.nn.LSTMCell() & torch.nn.LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个单步的 rnn\n",
    "rnn_single = nn.RNNCell(input_size=100, hidden_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0083, -0.0017, -0.0677,  ..., -0.0704, -0.0362,  0.0629],\n",
       "        [ 0.0239, -0.0640, -0.0293,  ..., -0.0418,  0.0042, -0.0208],\n",
       "        [ 0.0417,  0.0106, -0.0342,  ...,  0.0124, -0.0031, -0.0418],\n",
       "        ...,\n",
       "        [ 0.0638, -0.0256, -0.0199,  ..., -0.0173, -0.0097,  0.0149],\n",
       "        [ 0.0480, -0.0320, -0.0168,  ..., -0.0290, -0.0562,  0.0531],\n",
       "        [-0.0359,  0.0138, -0.0278,  ...,  0.0099,  0.0323, -0.0372]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 访问其中的参数\n",
    "rnn_single.weight_hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 200])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 访问其中的参数\n",
    "rnn_single.weight_hh.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start (RNNCell)\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"css/rnn.jpeg\" width=\"70%\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x input =  torch.Size([6, 5, 100])\n",
      "init state =  torch.Size([5, 200])\n",
      " \n",
      "final state output =  torch.Size([5, 200])\n",
      "get 6 output in out\n"
     ]
    }
   ],
   "source": [
    "# 定义一个单步的 rnn\n",
    "rnn_single = nn.RNNCell(input_size=100, hidden_size=200)\n",
    "\n",
    "# 构造一个序列，长为 6，batch 是 5， 特征是 100\n",
    "x = Variable(torch.randn(6, 5, 100)) # 这是 rnn 的输入格式\n",
    "\n",
    "# 定义初始的记忆状态\n",
    "h_t = Variable(torch.zeros(5, 200))\n",
    "\n",
    "\n",
    "# 传入 rnn\n",
    "out = []\n",
    "for i in range(6): # 通过循环 6 次作用在整个序列上\n",
    "    h_t = rnn_single(x[i], h_t)\n",
    "    out.append(h_t)\n",
    "    \n",
    "    \n",
    "print(\"x input = \", x.size() )\n",
    "print(\"init state = \", h_t.size() )\n",
    "print(\" \")\n",
    "print(\"final state output = \", h_t.size())\n",
    "\n",
    "print(\"get {} output in out\".format(len(out)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start (RNN)\n",
    "\n",
    "- 一般情况下我们都是用 nn.RNN() 而不是 nn.RNNCell()，\n",
    "- 因为 nn.RNN() 能够避免我们手动写循环，非常方便，\n",
    "- 同时如果不特别说明，我们也会选择使用默认的全 0 初始化隐藏状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_seq = nn.RNN(100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0213,  0.0327, -0.0550,  ...,  0.0291, -0.0205, -0.0494],\n",
       "        [-0.0030, -0.0407,  0.0207,  ..., -0.0018,  0.0182,  0.0278],\n",
       "        [ 0.0237,  0.0191,  0.0400,  ..., -0.0562, -0.0289, -0.0374],\n",
       "        ...,\n",
       "        [-0.0459,  0.0371, -0.0044,  ...,  0.0271, -0.0448,  0.0354],\n",
       "        [ 0.0267, -0.0429,  0.0241,  ..., -0.0197, -0.0009,  0.0148],\n",
       "        [-0.0290,  0.0197,  0.0474,  ...,  0.0221,  0.0477,  0.0478]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 访问其中的参数\n",
    "rnn_seq.weight_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 200])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_seq.weight_hh_l0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final state output =  torch.Size([1, 5, 200])\n",
      " \n",
      "get 6 output in out\n",
      "out = torch.Size([6, 5, 200])\n"
     ]
    }
   ],
   "source": [
    "rnn_seq = nn.RNN(100, 200)\n",
    "\n",
    "# 使用默认的全 0 隐藏状态\n",
    "out, h_t = rnn_seq(x) \n",
    "\n",
    "# 这里的 h_t 是网络最后的隐藏状态\n",
    "# 网络也输出了 6 个 output， out = (seq, batch, feature)\n",
    "print(\"final state output = \", h_t.size())\n",
    "\n",
    "print(\" \")\n",
    "print(\"get {} output in out\".format(len(out)))\n",
    "print(\"out = {}\".format(out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final state output =  torch.Size([1, 5, 200])\n",
      " \n",
      "get 6 output in out\n",
      "out = torch.Size([6, 5, 200])\n"
     ]
    }
   ],
   "source": [
    "rnn_seq = nn.RNN(100, 200)\n",
    "\n",
    "# 自己定义初始的隐藏状态\n",
    "# 这里的隐藏状态的大小有三个维度，分别是 (num_layers * num_direction, batch, hidden_size)\n",
    "h_0 = Variable(torch.randn(1, 5, 200))\n",
    "\n",
    "out, h_t = rnn_seq(x, h_0)\n",
    "\n",
    "\n",
    "print(\"final state output = \", h_t.size())\n",
    "print(\" \")\n",
    "print(\"get {} output in out\".format(len(out)))\n",
    "print(\"out = {}\".format(out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 5, 200])\n",
      "6 5 200\n"
     ]
    }
   ],
   "source": [
    "s, b, h = out.shape\n",
    "print(out.shape)\n",
    "print(s,b,h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"css/lstm.jpeg\" width=\"70%\"/>\n",
    "</div>\n",
    "\n",
    "- 注意这里 LSTM 输出的隐藏状态有两个，h 和 c，就是上图中的每个 cell 之间的两个箭头，这两个隐藏状态的大小都是相同的\n",
    "- (num_layers * direction, batch, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_seq = nn.LSTM(50, 100, num_layers=2) # 输入维度 100，输出 200，两层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0676,  0.0521, -0.0513,  ..., -0.0539, -0.0024,  0.0850],\n",
       "        [ 0.0501,  0.0255, -0.0657,  ...,  0.0357,  0.0838, -0.0272],\n",
       "        [-0.0853,  0.0025,  0.0305,  ...,  0.0430, -0.0423, -0.0073],\n",
       "        ...,\n",
       "        [ 0.0264, -0.0014,  0.0088,  ..., -0.0227,  0.0053,  0.0405],\n",
       "        [-0.0515,  0.0842, -0.0931,  ...,  0.0984, -0.0607,  0.0590],\n",
       "        [-0.0228, -0.0989, -0.0457,  ...,  0.0791, -0.0570, -0.0397]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_seq.weight_hh_l0 # 第一层的 h_t 权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 100])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_seq.weight_hh_l0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_seq = nn.LSTM(50, 100, num_layers=2) # 输入维度 100，输出 200，两层\n",
    "\n",
    "lstm_input = Variable(torch.randn(10, 3, 50)) # 序列 10，batch 是 3，输入维度 50\n",
    "\n",
    "out, (h, c) = lstm_seq(lstm_input) # 使用默认的全 0 隐藏状态, 注意这里 LSTM 输出的隐藏状态有两个，h 和 c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 100])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape # 两层，Batch 是 3，特征是 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 100])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 100])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不使用默认的隐藏状态\n",
    "\n",
    "lstm_seq = nn.LSTM(50, 100, num_layers=2) # 输入维度 100，输出 200，两层\n",
    "\n",
    "lstm_input = Variable(torch.randn(10, 3, 50)) # 序列 10，batch 是 3，输入维度 50\n",
    "h_init = Variable(torch.randn(2, 3, 100))\n",
    "c_init = Variable(torch.randn(2, 3, 100))\n",
    "\n",
    "out, (h, c) = lstm_seq(lstm_input, (h_init, c_init)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 100])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 100])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 100])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"css/gru.jpeg\" width=\"70%\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_seq = nn.GRU(10, 20)\n",
    "\n",
    "gru_input = Variable(torch.randn(3, 32, 10))\n",
    "\n",
    "out, h = gru_seq(gru_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0282, -0.1897, -0.1052,  ..., -0.1062,  0.1588, -0.0910],\n",
       "        [-0.0097,  0.1193,  0.0938,  ...,  0.1145, -0.1565,  0.1870],\n",
       "        [-0.1643,  0.0829,  0.1664,  ...,  0.0507, -0.1210, -0.1360],\n",
       "        ...,\n",
       "        [-0.0405,  0.1974, -0.0814,  ..., -0.1745,  0.1608,  0.1269],\n",
       "        [ 0.2109, -0.0397, -0.0079,  ...,  0.0957, -0.1421,  0.2173],\n",
       "        [-0.0900, -0.1897, -0.1490,  ..., -0.1499, -0.1126, -0.1607]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_seq.weight_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 20])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_seq.weight_hh_l0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 20])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 20])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

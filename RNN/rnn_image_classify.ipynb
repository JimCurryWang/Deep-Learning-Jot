{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rnn in image recognition\n",
    "\n",
    "Reference: https://wizardforcel.gitbooks.io/learn-dl-with-pytorch-liaoxingyu/content/5.2.html\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"css/rnn_image_1.jpg\" width=\"50%\"/>\n",
    "  <img src=\"css/rnn_image_2.jpg\" width=\"50%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms as tfs\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# torchvision.datasets\n",
    "# https://www.aiworkbox.com/lessons/load-mnist-dataset-from-pytorch-torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据\n",
    "data_tf = tfs.Compose([\n",
    "    tfs.ToTensor(),\n",
    "    tfs.Normalize([0.5], [0.5]) # 标准化\n",
    "])\n",
    "\n",
    "train_set = MNIST('./data', train=True, transform=data_tf, download=True)\n",
    "test_set = MNIST('./data', train=False, transform=data_tf, download=True)\n",
    "\n",
    "#train_data = DataLoader(train_set, 64, True, num_workers=4)\n",
    "#test_data = DataLoader(test_set, 128, False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "# (seq, batch, feature)\n",
    "# (seq=num_layers*num_direction, batch, feature=hidden_size )\n",
    "\n",
    "class rnn_classify(nn.Module):\n",
    "    def __init__(self, in_feature=28, hidden_feature=100, num_class=10, num_layers=2):\n",
    "        '''\n",
    "        in_feature=28, hidden_feature=100\n",
    "        使用两层 lstm\n",
    "        The final class = 10\n",
    "        '''\n",
    "        super(rnn_classify, self).__init__()\n",
    "        self.rnn = nn.LSTM(in_feature, hidden_feature, num_layers)\n",
    "        self.classifier = nn.Linear(hidden_feature, num_class) # 将最后一个 rnn 的输出使用全连接得到最后的分类结果\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x 大小为 (batch, 1, 28, 28)，所以我们需要将其转换成 RNN 的输入形式，即 (28, batch, 28)\n",
    "        '''\n",
    "        x = x.squeeze() # 去掉 (batch, 1, 28, 28) 中的 1，变成 (batch, 28, 28)\n",
    "        x = x.permute(2, 0, 1) # 将最后一维放到第一维，变成 (28, batch, 28)\n",
    "        out, _ = self.rnn(x) # 使用默认的隐藏状态，得到的 out 是 (28, batch, hidden_feature)\n",
    "        out = out[-1, :, :] # 取序列中的最后一个，大小是 (batch, hidden_feature)\n",
    "        out = self.classifier(out) # 得到分类结果\n",
    "        return out\n",
    "    \n",
    "\n",
    "net = rnn_classify()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimzier = torch.optim.Adadelta(net.parameters(), 1e-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# squeeze and unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([1, 3, 3])\n",
      "\n",
      "squeeze data: tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "squeeze(0) shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(\n",
    "    [[[0, 1, 2],\n",
    "      [3, 4, 5],\n",
    "      [6, 7, 8],]] \n",
    ")\n",
    "\n",
    "print('Shape:', data.shape)\n",
    "print(\"\")\n",
    "\n",
    "# squeeze()\n",
    "squeeze_data = data.squeeze(0)\n",
    "print('squeeze data:', squeeze_data)\n",
    "print('squeeze(0) shape:', squeeze_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([1, 3, 3])\n",
      "\n",
      "unsqueeze data: tensor([[[[0, 1, 2],\n",
      "          [3, 4, 5],\n",
      "          [6, 7, 8]]]])\n",
      "unsqueeze(0) shape: torch.Size([1, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor([\n",
    "    [[0, 1, 2],\n",
    "     [3, 4, 5],\n",
    "     [6, 7, 8],]\n",
    "])\n",
    "\n",
    "print('Shape:', data.shape)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# unsqueeze()\n",
    "unsqueeze_data = data.unsqueeze(0)\n",
    "print('unsqueeze data:', unsqueeze_data)\n",
    "print('unsqueeze(0) shape:', unsqueeze_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View\n",
    "\n",
    "https://pytorch.org/docs/stable/tensors.html?highlight=view#torch.Tensor.view\n",
    "\n",
    "**view(*shape) → Tensor**    \n",
    "- Returns a new tensor with the same data as the self tensor but of a different shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.view(16)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1, 2, 3, 4)\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(b, c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
